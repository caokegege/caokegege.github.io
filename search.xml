<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java集合及concurrent并发包总结]]></title>
    <url>%2F2018%2F04%2F27%2FJava%E9%9B%86%E5%90%88%E5%8F%8Aconcurrent%E5%B9%B6%E5%8F%91%E5%8C%85%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.集合包 集合包最常用的有Collection和Map两个接口的实现类，Colleciton用于存放多个单对象，Map用于存放Key-Value形式的键值对。 Collection中最常用的又分为两种类型的接口：List和Set，两者最明显的差别为List支持放入重复的元素，而Set不支持。 List最常用的实现类有：ArrayList、LinkedList、Vector及Stack；Set接口常用的实现类有：HashSet、TreeSet。 1.1 ArrayList ArrayList基于数组方式实现，默认构造器通过调用ArrayList(int)来完成创建，传入的值为10，实例化了一个Object数组，并将此数组赋给了当前实例的elementData属性，此Object数组的大小即为传入的initialCapacity，因此调用空构造器的情况下会创建一个大小为10的Object数组。 插入对象：add(E) 基于已有元素数量加1作为名叫minCapacity的变量，比较此值和Object数组的大小，若大于数组值，那么先将当前Object数组值赋给一个数组对象，接着产生一个鑫的数组容量值。此值的计算方法为当前数组值*1.5+1，如得出的容量值仍然小于minCapacity，那么就以minCapacity作为新的容量值，调用Arrays.copyOf来生成新的数组对象。 还提供了add(int,E)这样的方法将元素直接插入指定的int位置上，将目前index及其后的数据都往后挪一位，然后才能将指定的index位置的赋值为传入的对象，这种方式要多付出一次复制数组的代价。还提供了addAll 删除对象：remove(E) 这里调用了faseRemove方法将index后的对象往前复制一位，并将数组中的最后一个元素的值设置为null，即释放了对此对象的引用。 还提供了remove(int)方法来删除指定位置的对象，remove(int)的实现比remove(E)多了一个数组范围的检测，但少了对象位置的查找，因此性能会更好。 获取单个对象：get(int) 遍历对象：iterator() 判断对象是否存在：contains(E) 总结： 1，ArrayList基于数组方式实现，无容量的限制； 2，ArrayList在执行插入元素时可能要扩容，在删除元素时并不会减小数组的容量（如希望相应的缩小数组容量，可以调用ArrayList的trimToSize()），在查找元素时要遍历数组，对于非null的元素采取equals的方式寻找； 3，ArrayList是非线程安全的。 1.2 LinkedList LinkedList基于双向链表机制，所谓双向链表机制，就是集合中的每个元素都知道其前一个元素及其后一个元素的位置。在LinkedList中，以一个内部的Entry类来代表集合中的元素，元素的值赋给element属性，Entry中的next属性指向元素的后一个元素，Entry中的previous属性指向元素的前一个元素，基于这样的机制可以快速实现集合中元素的移动。 总结： 1，LinkedList基于双向链表机制实现； 2，LinkedList在插入元素时，须创建一个新的Entry对象，并切换相应元素的前后元素的引用；在查找元素时，须遍历链表；在删除元素时，要遍历链表，找到要删除的元素，然后从链表上将此元素删除即可，此时原有的前后元素改变引用连在一起； 3，LinkedList是非线程安全的。 1.3 Vector 其add、remove、get(int)方法都加了synchronized关键字，默认创建一个大小为10的Object数组，并将capacityIncrement设置为0。容量扩充策略：如果capacityIncrement大于0，则将Object数组的大小扩大为现有size加上capacityIncrement的值；如果capacity等于或小于0，则将Object数组的大小扩大为现有size的两倍，这种容量的控制策略比ArrayList更为可控。 Vector是基于Synchronized实现的线程安全的ArrayList，但在插入元素时容量扩充的机制和ArrayList稍有不同，并可通过传入capacityIncrement来控制容量的扩充。 1.4 Stack Stack继承于Vector，在其基础上实现了Stack所要求的后进先出(LIFO)的弹出与压入操作，其提供了push、pop、peek三个主要的方法： push操作通过调用Vector中的addElement来完成； pop操作通过调用peek来获取元素，并同时删除数组中的最后一个元素； peek操作通过获取当前Object数组的大小，并获取数组上的最后一个元素。 1.5 HashSet 默认构造创建一个HashMap对象 add(E)：调用HashMap的put方法来完成此操作，将需要增加的元素作为Map中的key，value则传入一个之前已创建的Object对象。 remove(E)：调用HashMap的remove(E)方法完成此操作。 contains(E)：HashMap的containsKey iterator()：调用HashMap的keySet的iterator方法。 HashSet不支持通过get(int)获取指定位置的元素，只能自行通过iterator方法来获取。 总结： 1，HashSet基于HashMap实现，无容量限制； 2，HashSet是非线程安全的。 1.6 TreeSet TreeSet和HashSet的主要不同在于TreeSet对于排序的支持，TreeSet基于TreeMap实现。 1.7 HashMap HashMap空构造，将loadFactor设为默认的0.75，threshold设置为12，并创建一个大小为16的Entry对象数组。 基于数组+链表的结合体(链表散列)实现，将key-value看成一个整体，存放于Entity[]数组，put的时候根据key hash后的hashcode和数组length-1按位与的结果值判断放在数组的哪个位置，如果该数组位置上若已经存放其他元素，则在这个位置上的元素以链表的形式存放。如果该位置上没有元素则直接存放。 当系统决定存储HashMap中的key-value对时，完全没有考虑Entry中的value，仅仅只是根据key来计算并决定每个Entry的存储位置。我们完全可以把Map集合中的value当成key的附属，当系统决定了key的存储位置之后，value随之保存在那里即可。get取值也是根据key的hashCode确定在数组的位置，在根据key的equals确定在链表处的位置。121 while (capacity &lt; initialCapacity)2 capacity &lt;&lt;= 1; 以上代码保证了初始化时HashMap的容量总是2的n次方，即底层数组的长度总是为2的n次方。它通过h &amp; (table.length -1) 来得到该对象的保存位，若length为奇数值，则与运算产生相同结果，便会形成链表，尽可能的少出现链表才能提升hashMap的效率，所以这是hashMap速度上的优化。 扩容resize(): 当HashMap中的元素越来越多的时候，hash冲突的几率也就越来越高，因为数组的长度是固定的。所以为了提高查询的效率，就要对HashMap的数组进行扩容，而在HashMap数组扩容之后，最消耗性能的点就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是resize。那么HashMap什么时候进行扩容呢？当HashMap中的元素个数超过数组大小*loadFactor时，就会进行数组扩容，loadFactor的默认值为0.75，这是一个折中的取值。 负载因子衡量的是一个散列表的空间的使用程度，负载因子越大表示散列表的装填程度越高，反之愈小。负载因子越大，对空间的利用更充分，然而后果是查找效率的降低；如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费。 HashMap的实现中，通过threshold字段来判断HashMap的最大容量。threshold就是在此loadFactor和capacity对应下允许的最大元素数目，超过这个数目就重新resize，以降低实际的负载因子。默认的的负载因子0.75是对空间和时间效率的一个平衡选择。 initialCapacity*2，成倍扩大容量，HashMap(int initialCapacity, float loadFactor)：以指定初始容量、指定的负载因子创建一个 HashMap。不设定参数，则初始容量值为16，默认的负载因子为0.75，不宜过大也不宜过小，过大影响效率，过小浪费空间。扩容后需要重新计算每个元素在数组中的位置，是一个非常消耗性能的操作，所以如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能。 HashTable数据结构的原理大致一样，区别在于put、get时加了同步关键字，而且HashTable不可存放null值。 在高并发时可以使用ConcurrentHashMap，其内部使用锁分段技术，维持这锁Segment的数组，在数组中又存放着Entity[]数组，内部hash算法将数据较均匀分布在不同锁中。 总结： 1，HashMap采用数组方式存储key、value构成的Entry对象，无容量限制； 2，HashMap基于key hash寻找Entry对象存放到数组的位置，对于hash冲突采用链表的方式解决； 3，HashMap在插入元素时可能会扩大数组的容量，在扩大容量时须要重新计算hash，并复制对象到新的数组中； 4，HashMap是非线程安全的。 详细说明：http://zhangshixi.iteye.com/blog/672697 1.8 TreeMap TreeMap基于红黑树的实现，因此它要求一定要有key比较的方法，要么传入Comparator实现，要么key对象实现Comparable借口。在put操作时，基于红黑树的方式遍历，基于comparator来比较key应放在树的左边还是右边，如找到相等的key，则直接替换掉value。 2.并发包 jdk5.0一很重要的特性就是增加了并发包java.util.concurrent.*，在说具体的实现类或接口之前，这里先简要说下Java内存模型、volatile变量及AbstractQueuedSynchronizer(以下简称AQS同步器)，这些都是并发包众多实现的基础。 Java内存模型 描述了线程内存与主存见的通讯关系。定义了线程内的内存改变将怎样传递到其他线程的规则，同样也定义了线程内存与主存进行同步的细节，也描述了哪些操作属于原子操作及操作间的顺序。 代码顺序规则： 一个线程内的每个动作happens-before同一个线程内在代码顺序上在其后的所有动作. volatile变量规则： 对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入. 传递性： 如果A happens-before B, B happens-before C, 那么A happens-before C. volatile 当我们声明共享变量为volatile后，对这个变量的读/写将会很特别。理解volatile特性的一个好方法是：把对volatile变量的单个读/写，看成是使用同一个监视器锁对这些单个读/写操作做了同步。 监视器锁的happens-before规则保证释放监视器和获取监视器的两个线程之间的内存可见性，这意味着对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。 简而言之，volatile变量自身具有下列特性： 可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。 原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。 volatile写的内存语义如下： 当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存。 volatile读的内存语义如下： 当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。 下面对volatile写和volatile读的内存语义做个总结： 线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了（其对共享变量所在修改的）消息。 线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息。 线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。 锁释放-获取与volatile的读写具有相同的内存语义， 锁释放的内存语义如下： 当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存。 锁获取的内存语义如下： 当线程获取锁时，JMM会把该线程对应的本地内存置为无效，从而使得被监视器保护的临界区代码必须要从主内存中读取共享变量。 下面对锁释放和锁获取的内存语义做个总结： 线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A对共享变量所做修改的）消息。 线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改的）消息。 线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发送消息。示例：123456789101112131415161718192021222324252627282930313233class VolatileExample &#123; int x = 0; volatile int b = 0; private void write() &#123; x = 5; b = 1; &#125; private void read() &#123; int dummy = b; while (x != 5) &#123; &#125; &#125; public static void main(String[] args) throws Exception &#123; final VolatileExample example = new VolatileExample(); Thread thread1 = new Thread(new Runnable() &#123; public void run() &#123; example.write(); &#125; &#125;); Thread thread2 = new Thread(new Runnable() &#123; public void run() &#123; example.read(); &#125; &#125;); thread1.start(); thread2.start(); thread1.join(); thread2.join(); &#125;&#125; 若thread1先于thread2执行，则程序执行流程分析如上图所示，thread2读的结果是dummy=1，x=5所以不会进入死循环。 但并不能保证两线程的执行顺序，若thread2先于thread1执行，则程序在两线程join中断之前的结果为：因为b变量的类型是volatile，故thread1写之后，thread2即可读到b变量的值发生变化， 而x是普通变量，故最后情况是dummy=1，但thread2的读操作因为x=0而进入死循环中。 在JSR-133之前的旧Java内存模型中，虽然不允许volatile变量之间重排序，但旧的Java内存模型仍然会允许volatile变量与普通变量之间重排序。JSR-133则增强了volatile的内存语义：严格限制编译器（在编译期）和处理器（在运行期）对volatile变量与普通变量的重排序，确保volatile的写-读和监视器的释放-获取一样，具有相同的内存语义。限制重排序是通过内存屏障实现的，具体可见JMM的描述。 由于volatile仅仅保证对单个volatile变量的读/写具有原子性，而监视器锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性。在功能上，监视器锁比volatile更强大；在可伸缩性和执行性能上，volatile更有优势。如果读者想在程序中用volatile代替监视器锁，请一定谨慎。 AbstractQueuedSynchronizer (AQS) AQS使用一个整型的volatile变量（命名为state）来维护同步状态，这是接下来实现大部分同步需求的基础。提供了一个基于FIFO队列，可以用于构建锁或者其他相关同步装置的基础框架。使用的方法是继承，子类通过继承同步器并需要实现它的方法来管理其状态，管理的方式就是通过类似acquire和release的方式来操纵状态。然而多线程环境中对状态的操纵必须确保原子性，因此子类对于状态的把握，需要使用这个同步器提供的以下三个方法对状态进行操作：123456java.util.concurrent.locks.AbstractQueuedSynchronizer.getState()java.util.concurrent.locks.AbstractQueuedSynchronizer.setState(int)java.util.concurrent.locks.AbstractQueuedSynchronizer.compareAndSetState(int, int) 子类推荐被定义为自定义同步装置的内部类，同步器自身没有实现任何同步接口，它仅仅是定义了若干acquire之类的方法来供使用。该同步器即可以作为排他模式也可以作为共享模式，当它被定义为一个排他模式时，其他线程对其的获取就被阻止，而共享模式对于多个线程获取都可以成功。 同步器是实现锁的关键，利用同步器将锁的语义实现，然后在锁的实现中聚合同步器。可以这样理解：锁的API是面向使用者的，它定义了与锁交互的公共行为，而每个锁需要完成特定的操作也是透过这些行为来完成的（比如：可以允许两个线程进行加锁，排除两个以上的线程），但是实现是依托给同步器来完成；同步器面向的是线程访问和资源控制，它定义了线程对资源是否能够获取以及线程的排队等操作。锁和同步器很好的隔离了二者所需要关注的领域，严格意义上讲，同步器可以适用于除了锁以外的其他同步设施上（包括锁）。同步器的开始提到了其实现依赖于一个FIFO队列，那么队列中的元素Node就是保存着线程引用和线程状态的容器，每个线程对同步器的访问，都可以看做是队列中的一个节点。 对于一个独占锁的获取和释放有如下伪码可以表示： 获取一个排他锁12345678910while(获取锁) &#123; if (获取到) &#123; 退出while循环 &#125; else &#123; if(当前线程没有入队列) &#123; 那么入队列 &#125; 阻塞当前线程 &#125;&#125; 释放一个排他锁12341 if (释放成功) &#123;2 删除头结点3 激活原头结点的后继节点4 &#125; 示例： 下面通过一个排它锁的例子来深入理解一下同步器的工作原理，而只有掌握同步器的工作原理才能更加深入了解其他的并发组件。 排他锁的实现，一次只能一个线程获取到锁：12345678910111213141516171819202122232425262728293031323334353637383940414243public class Mutex implements Lock, java.io.Serializable &#123; // 内部类，自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; // 是否处于占用状态 protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; // 当状态为0的时候获取锁 public boolean tryAcquire(int acquires) &#123; assert acquires == 1; // Otherwise unused if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; // 释放锁，将状态设置为0 protected boolean tryRelease(int releases) &#123; assert releases == 1; // Otherwise unused if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; &#125; // 返回一个Condition，每个condition都包含了一个condition队列 Condition newCondition() &#123; return new ConditionObject(); &#125; &#125; // 仅需要将操作代理到Sync上即可 private final Sync sync = new Sync(); public void lock() &#123; sync.acquire(1); &#125; public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; public void unlock() &#123; sync.release(1); &#125; public Condition newCondition() &#123; return sync.newCondition(); &#125; public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125; public boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads(); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125; &#125; 可以看到Mutex将Lock接口均代理给了同步器的实现。使用方将Mutex构造出来后，调用lock获取锁，调用unlock将锁释放。 获取锁，acquire(int arg)的主要逻辑包括： 尝试获取（调用tryAcquire更改状态，需要保证原子性）； 在tryAcquire方法中适用了同步器提供的对state操作的方法，利用compareAndSet保证只有一个线程能够对状态进行成功修改，而没有成功修改的线程将进入sync队列排队。 如果获取不到，将当前线程构造成节点Node并加入sync队列； 进入队列的每个线程都是一个节点Node，从而形成了一个双向队列，类似CLH队列，这样做的目的是线程间的通信会被限制在较小规模（也就是两个节点左右）。 再次尝试获取，如果没有获取到那么将当前线程从线程调度器上摘下，进入等待状态。 释放锁，release(int arg)的主要逻辑包括： 尝试释放状态； tryRelease能够保证原子化的将状态设置回去，当然需要使用compareAndSet来保证。如果释放状态成功之后，就会进入后继节点的唤醒过程。 唤醒当前节点的后继节点所包含的线程。 通过LockSupport的unpark方法将休眠中的线程唤醒，让其继续acquire状态。 回顾整个资源的获取和释放过程： 在获取时，维护了一个sync队列，每个节点都是一个线程在进行自旋，而依据就是自己是否是首节点的后继并且能够获取资源； 在释放时，仅仅需要将资源还回去，然后通知一下后继节点并将其唤醒。 这里需要注意，队列的维护（首节点的更换）是依靠消费者（获取时）来完成的，也就是说在满足了自旋退出的条件时的一刻，这个节点就会被设置成为首节点。 队列里的节点线程的禁用和唤醒是通过LockSupport的park()及unpark()，调用的unsafe、底层也是native的实现。 关于java lock的浅析可见：http://jm-blog.aliapp.com/?p=414 共享模式和以上的独占模式有所区别，分别调用acquireShared(int arg)和releaseShared(int arg)获取共享模式的状态。 以文件的查看为例，如果一个程序在对其进行读取操作，那么这一时刻，对这个文件的写操作就被阻塞，相反，这一时刻另一个程序对其进行同样的读操作是可以进行的。如果一个程序在对其进行写操作， 那么所有的读与写操作在这一时刻就被阻塞，直到这个程序完成写操作。 以读写场景为例，描述共享和独占的访问模式，如下图所示： 上图中，红色代表被阻塞，绿色代表可以通过。 在上述对同步器AbstractQueuedSynchronizer进行了实现层面的分析之后，我们通过一个例子来加深对同步器的理解： 设计一个同步工具，该工具在同一时刻，只能有两个线程能够并行访问，超过限制的其他线程进入阻塞状态。 对于这个需求，可以利用同步器完成一个这样的设定，定义一个初始状态，为2，一个线程进行获取那么减1，一个线程释放那么加1，状态正确的范围在[0，1，2]三个之间，当在0时，代表再有新的线程对资源进行获取时只能进入阻塞状态（注意在任何时候进行状态变更的时候均需要以CAS作为原子性保障）。由于资源的数量多于1个，同时可以有两个线程占有资源，因此需要实现tryAcquireShared和tryReleaseShared方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class TwinsLock implements Lock &#123; private final Sync sync = new Sync(2); private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -7889272986162341211L; Sync(int count) &#123; if (count &lt;= 0) &#123; throw new IllegalArgumentException(&quot;count must large than zero.&quot;); &#125; setState(count); &#125; public int tryAcquireShared(int reduceCount) &#123; for (;;) &#123; int current = getState(); int newCount = current - reduceCount; if (newCount &lt; 0 || compareAndSetState(current, newCount)) &#123; return newCount; &#125; &#125; &#125; public boolean tryReleaseShared(int returnCount) &#123; for (;;) &#123; int current = getState(); int newCount = current + returnCount; if (compareAndSetState(current, newCount)) &#123; return true; &#125; &#125; &#125; &#125; public void lock() &#123; sync.acquireShared(1); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1); &#125; public boolean tryLock() &#123; return sync.tryAcquireShared(1) &gt;= 0; &#125; public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireSharedNanos(1, unit.toNanos(time)); &#125; public void unlock() &#123; sync.releaseShared(1); &#125; public Condition newCondition() &#123; return null; &#125;&#125; 这里我们编写一个测试来验证TwinsLock是否能够正常工作并达到预期。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class TwinsLockTest &#123; @Test public void test() &#123; final Lock lock = new TwinsLock(); class Worker extends Thread &#123; public void run() &#123; while (true) &#123; lock.lock(); try &#123; Thread.sleep(1000L); System.out.println(Thread.currentThread()); Thread.sleep(1000L); &#125; catch (Exception ex) &#123; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; &#125; for (int i = 0; i &lt; 10; i++) &#123; Worker w = new Worker(); w.start(); &#125; new Thread() &#123; public void run() &#123; while (true) &#123; try &#123; Thread.sleep(200L); System.out.println(); &#125; catch (Exception ex) &#123; &#125; &#125; &#125; &#125;.start(); try &#123; Thread.sleep(20000L); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 上述测试用例的逻辑主要包括： 打印线程 Worker在两次睡眠之间打印自身线程，如果一个时刻只能有两个线程同时访问，那么打印出来的内容将是成对出现。 分隔线程 不停的打印换行，能让Worker的输出看起来更加直观。 该测试的结果是在一个时刻，仅有两个线程能够获得到锁，并完成打印，而表象就是打印的内容成对出现。 利用CAS(compare and set)是不会进行阻塞的，只会一个返回成功，一个返回失败，保证了一致性。 CAS操作同时具有volatile读和volatile写的内存语义。 AQS这部分转载于http://ifeve.com/introduce-abstractqueuedsynchronizer/ 2.1 ConcurrentHashMap ConcurrentHashMap是线程安全的HashMap的实现，默认构造同样有initialCapacity和loadFactor属性，不过还多了一个concurrencyLevel属性，三属性默认值分别为16、0.75及16。其内部使用锁分段技术，维持这锁Segment的数组，在Segment数组中又存放着Entity[]数组，内部hash算法将数据较均匀分布在不同锁中。 put操作：并没有在此方法上加上synchronized，首先对key.hashcode进行hash操作，得到key的hash值。hash操作的算法和map也不同，根据此hash值计算并获取其对应的数组中的Segment对象(继承自ReentrantLock)，接着调用此Segment对象的put方法来完成当前操作。 ConcurrentHashMap基于concurrencyLevel划分出了多个Segment来对key-value进行存储，从而避免每次put操作都得锁住整个数组。在默认的情况下，最佳情况下可允许16个线程并发无阻塞的操作集合对象，尽可能地减少并发时的阻塞现象。 get(key) 首先对key.hashCode进行hash操作，基于其值找到对应的Segment对象，调用其get方法完成当前操作。而Segment的get操作首先通过hash值和对象数组大小减1的值进行按位与操作来获取数组上对应位置的HashEntry。在这个步骤中，可能会因为对象数组大小的改变，以及数组上对应位置的HashEntry产生不一致性，那么ConcurrentHashMap是如何保证的？ 对象数组大小的改变只有在put操作时有可能发生，由于HashEntry对象数组对应的变量是volatile类型的，因此可以保证如HashEntry对象数组大小发生改变，读操作可看到最新的对象数组大小。 在获取到了HashEntry对象后，怎么能保证它及其next属性构成的链表上的对象不会改变呢？这点ConcurrentHashMap采用了一个简单的方式，即HashEntry对象中的hash、key、next属性都是final的，这也就意味着没办法插入一个HashEntry对象到基于next属性构成的链表中间或末尾。这样就可以保证当获取到HashEntry对象后，其基于next属性构建的链表是不会发生变化的。 ConcurrentHashMap默认情况下采用将数据分为16个段进行存储，并且16个段分别持有各自不同的锁Segment，锁仅用于put和remove等改变集合对象的操作，基于volatile及HashEntry链表的不变性实现了读取的不加锁。这些方式使得ConcurrentHashMap能够保持极好的并发支持，尤其是对于读远比插入和删除频繁的Map而言，而它采用的这些方法也可谓是对于Java内存模型、并发机制深刻掌握的体现。 2.2 ReentrantLock 在并发包的开始部分介绍了volatile特性及AQS同步器，而这两部分正是ReentrantLock实现的基础。通过上面AQS的介绍及原理分析，可知道是以volatile维持的int类型的state值，来判断线程是执行还是在syn队列中等待。 ReentrantLock的实现不仅可以替代隐式的synchronized关键字，而且能够提供超过关键字本身的多种功能。 这里提到一个锁获取的公平性问题，如果在绝对时间上，先对锁进行获取的请求一定被先满足，那么这个锁是公平的，反之，是不公平的，也就是说等待时间最长的线程最有机会获取锁，也可以说锁的获取是有序的。ReentrantLock这个锁提供了一个构造函数，能够控制这个锁是否是公平的。 对于公平和非公平的定义是通过对同步器AbstractQueuedSynchronizer的扩展加以实现的，也就是tryAcquire的实现上做了语义的控制。 公平和非公平性的更多原理分析见于http://ifeve.com/reentrantlock-and-fairness/ 2.3 Condition Condition是并发包中提供的一个接口，典型的实现有ReentrantLock，ReentrantLock提供了一个mewCondition的方法，以便用户在同一个锁的情况下可以根据不同的情况执行等待或唤醒动作。典型的用法可参考ArrayBlockingQueue的实现，下面来看ReentrantLock中 newCondition的实现。 ReentrantLock.newCondition() 创建一个AbstractQueuedSynchronizer的内部类ConditionObject的对象实例。 ReentrantLock.newCondition().await() 将当前线程加入此condition的等待队列中，并将线程置为等待状态。 ReentrantLock.newCondition().signal() 从此condition的等待队列中获取一个等待节点，并将节点上的线程唤醒，如果要唤醒全部等待节点的线程，则调用signalAll方法。 2.4 CopyOnWriteArrayList CopyOnWriteArrayList是一个线程安全、并且在读操作时无锁的ArrayList，其具体实现方法如下。 CopyOnWriteArrayList() 和ArrayList不同，此步的做法为创建一个大小为0的数组。 add(E) add方法并没有加上synchronized关键字，它通过使用ReentrantLock来保证线程安全。此处和ArrayList的不同是每次都会创建一个新的Object数组，此数组的大小为当前数组大小加1，将之前数组中的内容复制到新的数组中，并将 新增加的对象放入数组末尾，最后做引用切换将新创建的数组对象赋值给全局的数组对象。 remove(E) 和add方法一样，此方法也通过ReentrantLock来保证其线程安全，但它和ArrayList删除元素采用的方式并不一样。 首先创建一个比当前数组小1的数组，遍历新数组，如找到equals或均为null的元素，则将之后的元素全部赋值给新的数组对象，并做引用切换，返回true；如未找到，则将当前的元素赋值给新的数组对象，最后特殊处理数组中的最后 一个元素，如最后一个元素等于要删除的元素，即将当前数组对象赋值为新创建的数组对象，完成删除操作，如最后一个元素也不等于要删除的元素，那么返回false。 此方法和ArrayList除了锁不同外，最大的不同在于其复制过程并没有调用System的arrayCopy来完成，理论上来说会导致性能有一定下降。 get(int) 此方法非常简单，直接获取当前数组对应位置的元素，这种方法是没有加锁保护的，因此可能会出现读到脏数据的现象。但相对而言，性能会非常高，对于写少读多且脏数据影响不大的场景而言是不错的选择。 iterator() 调用iterator方法后创建一个新的COWIterator对象实例，并保存了一个当前数组的快照，在调用next遍历时则仅对此快照数组进行遍历，因此遍历此list时不会抛出ConcurrentModificatiedException。 与ArrayList的性能对比，在读多写少的并发场景中，较之ArrayList是更好的选择，单线程以及多线程下增加元素及删除元素的性能不比ArrayList好 2.5 CopyOnWriteArraySet CopyOnWriteArraySet基于CopyOnWriteArrayList实现，其唯一的不同是在add时调用的是CopyOnWriteArrayList的addIfAbsent方法。保证了无重复元素，但在add时每次都要进行数组的遍历，因此性能会略低于上个。 2.6 ArrayBlockingQueue 2.7 ThreadPoolExecutor 与每次需要时都创建线程相比，线程池可以降低创建线程的开销，在线程执行结束后进行的是回收操作，提高对线程的复用。Java中主要使用的线程池是ThreadPoolExecutor，此外还有定时的线程池ScheduledThreadPoolExecutor。 Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。 比较重要的几个类： ExecutorService 真正的线程池接口 ScheduledExecutorService 和Time/TimeTask类似，解决需要任务重复执行的问题 ThreadPoolExecutor ExecutorService的默认实现 SchedulesThreadPoolExecutor 继承ThreadPoolExecutor的ScheduledExecutorService接口实现，周期性任务调度的类实现 要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在Executors类里面提供了一些静态工厂，生成一些常用的线程池。 newSingleThreadExecutor 创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 2.newFixedThreadPool 创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 newCachedThreadPool 创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程， 那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。 4.newScheduledThreadPool 创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。 PS：但需要注意使用，newSingleThreadExecutor和newFixedThreadPool将超过处理的线程放在队列中，但工作线程较多时，会引起过多内存被占用，而后两者返回的线程池是没有线程上线的，所以在使用时需要当心，创建过多的线程容易引起服务器的宕机。 使用ThreadPoolExecutor自定义线程池，具体使用时需根据系统及JVM的配置设置适当的参数，下面是一示例：1231 int corePoolSize = Runtime.getRuntime().availableProcessors();2 threadsPool = new ThreadPoolExecutor(corePoolSize, corePoolSize, 10l, TimeUnit.SECONDS,3 new LinkedBlockingQueue&lt;Runnable&gt;(2000)); 2.8 Future和FutureTask Future是一个接口，FutureTask是一个具体实现类。这里先通过两个场景看看其处理方式及优点。 场景1, 现在通过调用一个方法从远程获取一些计算结果，假设有这样一个方法： 1 HashMap data = getDataFromRemote();如果是最传统的同步方式的使用，我们将一直等待getDataFromRemote()的返回，然后才能继续后面的工作。这个函数是从远程获取数据的计算结果的，如果需要的时间很长，并且后面的那部分代码与这些数据没有关系的话，阻塞在这里等待结果就会比较浪费时间。如何改进呢？ 能够想到的办法就是调用函数后马上返回，然后继续向下执行，等需要用数据时再来用或者再来等待这个数据。具体实现有两种方式：一个是用Future，另一个使用回调。 Future的用法 1 Future future = getDataFromRemote2();2 //do something3 HashMap data = future.get();可以看到，我们调用的方法返回一个Future对象，然后接着进行自己的处理，后面通过future.get()来获取真正的返回值。也即，在调用了getDataFromRemote2后，就已经启动了对远程计算结果的获取，同时自己的线程还在继续处理，直到需要时再获取数据。来看一下getDataFromRemote2的实现： 12345671 privete Future&lt;HashMap&gt; getDataFromRemote2()&#123;2 return threadPool.submit(new Callable&lt;HashMap&gt;()&#123;3 public HashMap call() throws Exception&#123;4 return getDataFromRemote();5 &#125;6 &#125;);7 &#125; 可以看到，在getDataFromRemote2中还是使用了getDataFromRemote来完成具体操作，并且用到了线程池：把任务加入到线程池中，把Future对象返回出去。我们调用了getDataFromRemote2的线程，然后返回来继续下面的执行，而背后是另外的线程在进行远程调用及等待的工作。get方法也可设置超时时间参数，而不是一直等下去。 场景2， key-value的形式存储连接，若key存在则获取，若不存在这个key，则创建新连接并存储。 传统的方式会使用HashMap来存储并判断key是否存在而实现连接的管理。而这在高并发的时候会出现多次创建连接的现象。那么新的处理方式又是怎样呢？ 通过ConcurrentHashMap及FutureTask实现高并发情况的正确性，ConcurrentHashMap的分段锁存储满足数据的安全性又不影响性能，FutureTask的run方法调用Sync.innerRun方法只会执行Runnable的run方法一次(即使是高并发情况)。 2.9 并发容器 在JDK中，有一些线程不安全的容器，也有一些线程安全的容器。并发容器是线程安全容器的一种，但是并发容器强调的是容器的并发性，也就是说不仅追求线程安全，还要考虑并发性，提升在容器并发环境下的性能。 加锁互斥的方式确实能够方便地完成线程安全，不过代价是降低了并发性，或者说是串行了。而并发容器的思路是尽量不用锁，比较有代表性的是以CopyOnWrite和Concurrent开头的几个容器。CopyOnWrite容器的思路是在更改容器的时候，把容器写一份进行修改，保证正在读的线程不受影响，这种方式用在读多写少的场景中会非常好，因为实质上是在写的时候重建了一次容器。而以Concurrent开头的容器的具体实现方式则不完全相同，总体来说是尽量保证读不加锁，并且修改时不影响读，所以达到比使用读写锁更高的并发性能。比如上面所说的ConcurrentHashMap，其他的并发容器的具体实现，可直接分析JDK中的源码。]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap和CopyOnWriteArrayList]]></title>
    <url>%2F2018%2F04%2F27%2FConcurrentHashMap%E5%92%8CCopyOnWriteArrayList%2F</url>
    <content type="text"><![CDATA[ConcurrentHashMap ConcurrentHashMap其实就是线程安全版本的hashMap。简单的解释就是通过把整个Map分为N个Segment（类似HashTable），这样每个HashTable之间就线程就不会发生冲突，可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。 CopyOnWriteArrayList 2.1 CopyOnWriteArrayList是线程安全版本的ArrayList。 2.2 什么是CopyOnWrite容器（写的时候复制）CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。 2.3 CopyOnWriteArrayList的实现原理在使用CopyOnWriteArrayList之前，我们先阅读其源码了解下它是如何实现的。 2.3.1 写的时候：需要加锁以下代码是向CopyOnWriteArrayList中add方法的实现（向CopyOnWriteArrayList里添加元素），可以发现在添加的时候是需要加锁的，否则多线程写的时候会Copy出N个副本出来。 2.3.2 读的时候：不需要加锁读的时候不需要加锁，如果读的时候有多个线程正在向CopyOnWriteArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的CopyOnWriteArrayList。 2.4 相对于Arraylist线程安全，相对于vector，第一不会出现迭代器异常，第二提高了效率： 2.4.1 迭代器异常（快速失败）：java中，集合在遍历的时候，如果内部被修改了会抛出java.util.ConcurrentModificationException错误。list和vector都会抛出 2.4.2 快速失败快速失败是指某个线程在迭代vector的时候，不允许其他线程修改该vector的内容，这样迭代器迭代出来的结果就会不准确，如用iterator迭代collection的时候，iterator就是另外起的一个线程，它去迭代collection，如果此时用collection.remove(obj)这个方法修改了collection里面的内容的时候，就会出现ConcurrentModificationException异常,这时候该迭代器就快速失败。通俗解释：就好像有一盘饺子，你要数数有几个，在你还没数完，其他人有放入（或拿走）了几个饺子。你就只能重新再数了。本来你数数就很快，但是，就有人比你手更快。 2.4.3 读的效率提高了由于都操作没有加锁，所以没有线程冲突；但写操作由于加锁，并采取了复制，所以效率更加低。所以此方法适用于读多写少修改少的应用。一、阻塞队列 BlockingQueue.class，阻塞队列接口BlockingDeque.class，双端阻塞队列接口ArrayBlockingQueue.class，阻塞队列，数组实现LinkedBlockingDeque.class，阻塞双端队列，链表实现LinkedBlockingQueue.class，阻塞队列，链表实现DelayQueue.class，阻塞队列，并且元素是Delay的子类，保证元素在达到一定时间后才可以取得到PriorityBlockingQueue.class，优先级阻塞队列SynchronousQueue.class，同步队列，但是队列长度为0，生产者放入队列的操作会被阻塞，直到消费者过来取，所以这个队列根本不需要空间存放元素；有点像一个独木桥，一次只能一人通过，还不能在桥上停留二、非阻塞队列： ConcurrentLinkedDeque.class，非阻塞双端队列，链表实现ConcurrentLinkedQueue.class，非阻塞队列，链表实现 三、转移队列： TransferQueue.class，转移队列接口，生产者要等消费者消费的队列，生产者尝试把元素直接转移给消费者LinkedTransferQueue.class，转移队列的链表实现，它比SynchronousQueue更快 四、其它容器： ConcurrentMap.class，并发Map的接口，定义了putIfAbsent(k,v)、remove(k,v)、replace(k,oldV,newV)、replace(k,v)这四个并发场景下特定的方法ConcurrentHashMap.class，并发HashMapConcurrentNavigableMap.class，NavigableMap的实现类，返回最接近的一个元素ConcurrentSkipListMap.class，它也是NavigableMap的实现类（要求元素之间可以比较），同时它比ConcurrentHashMap更加scalable——ConcurrentHashMap并不保证它的操作时间，并且你可以自己来调整它的load factor；但是ConcurrentSkipListMap可以保证O(log n)的性能，同时不能自己来调整它的并发参数，只有你确实需要快速的遍历操作，并且可以承受额外的插入开销的时候，才去使用它ConcurrentSkipListSet.class，和上面类似，只不过map变成了setCopyOnWriteArrayList.class，copy-on-write模式的array list，每当需要插入元素，不在原list上操作，而是会新建立一个list，适合读远远大于写并且写时间并苛刻的场景CopyOnWriteArraySet.class，和上面类似，list变成set而已]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HashMap]]></title>
    <url>%2F2018%2F04%2F27%2FHashMap%2F</url>
    <content type="text"><![CDATA[HashMap和Hashtable的区别 HashMap几乎可以等价于Hashtable，除了HashMap是非synchronized的，并可以接受null(HashMap可以接受为null的键值(key)和值(value)，而Hashtable则不行)。 HashMap是非synchronized，而Hashtable是synchronized，这意味着Hashtable是线程安全的，多个线程可以共享一个Hashtable；而如果没有正确的同步的话，多个线程是不能共享HashMap的。Java 5提供了ConcurrentHashMap，它是HashTable的替代，比HashTable的扩展性更好。 另一个区别是HashMap的迭代器(Iterator)是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛出ConcurrentModificationException异常。但这并不是一个一定发生的行为，要看JVM。这条同样也是Enumeration和Iterator的区别。 由于Hashtable是线程安全的也是synchronized，所以在单线程环境下它比HashMap要慢。如果你不需要同步，只需要单一线程，那么使用HashMap性能要好过Hashtable。 HashMap不能保证随着时间的推移Map中的元素次序是不变的。 要注意的一些重要术语：1) sychronized意味着在一次仅有一个线程能够更改Hashtable。就是说任何线程要更新Hashtable时要首先获得同步锁，其它线程要等到同步锁被释放之后才能再次获得同步锁更新Hashtable。 2) Fail-safe和iterator迭代器相关。如果某个集合对象创建了Iterator或者ListIterator，然后其它的线程试图“结构上”更改集合对象，将会抛出ConcurrentModificationException异常。但其它线程可以通过set()方法更改集合对象是允许的，因为这并没有从“结构上”更改集合。但是假如已经从结构上进行了更改，再调用set()方法，将会抛出IllegalArgumentException异常。 3) 结构上的更改指的是删除或者插入一个元素，这样会影响到map的结构。 我们能否让HashMap同步？HashMap可以通过下面的语句进行同步：1Map m = Collections.synchronizeMap(hashMap); Java中ArrayList和LinkedList区别ArrayList和LinkedList的大致区别如下: ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。 对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。 对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。 ArrayList内部是使用可増长数组实现的，所以是用get和set方法是花费常数时间的，但是如果插入元素和删除元素，除非插入和删除的位置都在表末尾，否则代码开销会很大，因为里面需要数组的移动。LinkedList是使用双链表实现的，所以get会非常消耗资源，除非位置离头部很近。但是插入和删除元素花费常数时间。 Java多线程面试问题 进程和线程之间有什么不同？一个进程是一个独立(self contained)的运行环境，它可以被看作一个程序或者一个应用。而线程是在进程中执行的一个任务。Java运行环境是一个包含了不同的类和程序的单一进程。线程可以被称为轻量级进程。线程需要较少的资源来创建和驻留在进程中，并且可以共享进程中的资源。 多线程编程的好处是什么？在多线程程序中，多个线程被并发的执行以提高程序的效率，CPU不会因为某个线程需要等待资源而进入空闲状态。多个线程共享堆内存(heap memory)，因此创建多个线程去执行一些任务会比创建多个进程更好。举个例子，Servlets比CGI更好，是因为Servlets支持多线程而CGI不支持。 用户线程和守护线程有什么区别？当我们在Java程序中创建一个线程，它就被称为用户线程。一个守护线程是在后台执行并且不会阻止JVM终止的线程。当没有用户线程在运行的时候，JVM关闭程序并且退出。一个守护线程创建的子线程依然是守护线程。 我们如何创建一个线程？有两种创建线程的方法：一是实现Runnable接口，然后将它传递给Thread的构造函数，创建一个Thread对象；二是直接继承Thread类。若想了解更多可以阅读这篇关于如何在Java中创建线程的文章。 有哪些不同的线程生命周期？当我们在Java程序中新建一个线程时，它的状态是New。当我们调用线程的start()方法时，状态被改变为Runnable。线程调度器会为Runnable线程池中的线程分配CPU时间并且讲它们的状态改变为Running。其他的线程状态还有Waiting，Blocked 和Dead。读这篇文章可以了解更多关于线程生命周期的知识。 可以直接调用Thread类的run()方法么？当然可以，但是如果我们调用了Thread的run()方法，它的行为就会和普通的方法一样，为了在新的线程中执行我们的代码，必须使用Thread.start()方法。 如何让正在运行的线程暂停一段时间？我们可以使用Thread类的Sleep()方法让线程暂停一段时间。需要注意的是，这并不会让线程终止，一旦从休眠中唤醒线程，线程的状态将会被改变为Runnable，并且根据线程调度，它将得到执行。 你对线程优先级的理解是什么？每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度的实现，这个实现是和操作系统相关的(OS dependent)。我们可以定义线程的优先级，但是这并不能保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个int变量(从1-10)，1代表最低优先级，10代表最高优先级。 什么是线程调度器(Thread Scheduler)和时间分片(Time Slicing)？线程调度器是一个操作系统服务，它负责为Runnable状态的线程分配CPU时间。一旦我们创建一个线程并启动它，它的执行便依赖于线程调度器的实现。时间分片是指将可用的CPU时间分配给可用的Runnable线程的过程。分配CPU时间可以基于线程优先级或者线程等待的时间。线程调度并不受到Java虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先级）。 在多线程中，什么是上下文切换(context-switching)？上下文切换是存储和恢复CPU状态的过程，它使得线程执行能够从中断点恢复执行。上下文切换是多任务操作系统和多线程环境的基本特征。 你如何确保main()方法所在的线程是Java程序最后结束的线程？我们可以使用Thread类的joint()方法来确保所有程序创建的线程在main()方法退出前结束。这里有一篇文章关于Thread类的joint()方法。 线程之间是如何通信的？当线程间是可以共享资源时，线程间通信是协调它们的重要的手段。Object类中wait()\notify()\notifyAll()方法可以用于线程间通信关于资源的锁的状态。点击这里有更多关于线程wait, notify和notifyAll. 为什么线程通信的方法wait(), notify()和notifyAll()被定义在Object类里？Java的每个对象中都有一个锁(monitor也可以称为监视器) 并且wait()，notify()等方法用于等待对象的锁或者通知其他线程对象的监视器可用。在Java的线程中并没有可供任何对象使用的锁和同步器。这就是为什么这些方法是Object类的一部分，这样Java的每一个类都有用于线程间通信的基本方法 为什么wait(), notify()和notifyAll()必须在同步方法或者同步块中被调用？当一个线程需要调用对象的wait()方法的时候，这个线程必须拥有该对象的锁，接着它就会释放这个对象锁并进入等待状态直到其他线程调用这个对象上的notify()方法。同样的，当一个线程需要调用对象的notify()方法时，它会释放这个对象的锁，以便其他在等待的线程就可以得到这个对象锁。由于所有的这些方法都需要线程持有对象的锁，这样就只能通过同步来实现，所以他们只能在同步方法或者同步块中被调用。 为什么Thread类的sleep()和yield()方法是静态的？Thread类的sleep()和yield()方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，并避免程序员错误的认为可以在其他非运行线程调用这些方法。 如何确保线程安全？在Java中可以有很多方法来保证线程安全——同步，使用原子类(atomic concurrent classes)，实现并发锁，使用volatile关键字，使用不变类和线程安全类。在线程安全教程中，你可以学到更多。 volatile关键字在Java中有什么作用？当我们使用volatile关键字去修饰变量的时候，所以线程都会直接读取该变量并且不缓存它。这就确保了线程读取到的变量是同内存中是一致的。 同步方法和同步块，哪个是更好的选择？同步块是更好的选择，因为它不会锁住整个对象（当然你也可以让它锁住整个对象）。同步方法会锁住整个对象，哪怕这个类中有多个不相关联的同步块，这通常会导致他们停止执行并需要等待获得这个对象上的锁。 如何创建守护线程？使用Thread类的setDaemon(true)方法可以将线程设置为守护线程，需要注意的是，需要在调用start()方法前调用这个方法，否则会抛出IllegalThreadStateException异常。 什么是ThreadLocal?ThreadLocal用于创建线程的本地变量，我们知道一个对象的所有线程会共享它的全局变量，所以这些变量不是线程安全的，我们可以使用同步技术。但是当我们不想使用同步的时候，我们可以选择ThreadLocal变量。每个线程都会拥有他们自己的Thread变量，它们可以使用get()\set()方法去获取他们的默认值或者在线程内部改变他们的值。ThreadLocal实例通常是希望它们同线程状态关联起来是private static属性。在ThreadLocal例子这篇文章中你可以看到一个关于ThreadLocal的小程序。 什么是Thread Group？为什么建议使用它？ThreadGroup是一个类，它的目的是提供关于线程组的信息。 ThreadGroup API比较薄弱，它并没有比Thread提供了更多的功能。它有两个主要的功能：一是获取线程组中处于活跃状态线程的列表；二是设置为线程设置未捕获异常处理器(ncaught exception handler)。但在Java 1.5中Thread类也添加了setUncaughtExceptionHandler(UncaughtExceptionHandler eh) 方法，所以ThreadGroup是已经过时的，不建议继续使用。1234567t1.setUncaughtExceptionHandler(new UncaughtExceptionHandler()&#123;@Overridepublic void uncaughtException(Thread t, Throwable e) &#123; System.out.println(&quot;exception occured:&quot;+e.getMessage());&#125;&#125;); 什么是Java线程转储(Thread Dump)，如何得到它？线程转储是一个JVM活动线程的列表，它对于分析系统瓶颈和死锁非常有用。有很多方法可以获取线程转储——使用Profiler，Kill -3命令，jstack工具等等。我更喜欢jstack工具，因为它容易使用并且是JDK自带的。由于它是一个基于终端的工具，所以我们可以编写一些脚本去定时的产生线程转储以待分析。读这篇文档可以了解更多关于产生线程转储的知识。 什么是死锁(Deadlock)？如何分析和避免死锁？死锁是指两个以上的线程永远阻塞的情况，这种情况产生至少需要两个以上的线程和两个以上的资源。分析死锁，我们需要查看Java应用程序的线程转储。我们需要找出那些状态为BLOCKED的线程和他们等待的资源。每个资源都有一个唯一的id，用这个id我们可以找出哪些线程已经拥有了它的对象锁。避免嵌套锁，只在需要的地方使用锁和避免无限期等待是避免死锁的通常办法，阅读这篇文章去学习如何分析死锁。 什么是Java Timer类？如何创建一个有特定时间间隔的任务？java.util.Timer是一个工具类，可以用于安排一个线程在未来的某个特定时间执行。Timer类可以用安排一次性任务或者周期任务。java.util.TimerTask是一个实现了Runnable接口的抽象类，我们需要去继承这个类来创建我们自己的定时任务并使用Timer去安排它的执行。 这里有关于java Timer的例子。 什么是线程池？如何创建一个Java线程池？一个线程池管理了一组工作线程，同时它还包括了一个用于放置等待执行的任务的队列。java.util.concurrent.Executors提供了一个 java.util.concurrent.Executor接口的实现用于创建线程池。线程池例子展现了如何创建和使用线程池，或者阅读ScheduledThreadPoolExecutor例子，了解如何创建一个周期任务。 Java并发面试问题 什么是原子操作？在Java Concurrency API中有哪些原子类(atomic classes)？原子操作是指一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须的手段。int++并不是一个原子操作，所以当一个线程读取它的值并加1时，另外一个线程有可能会读到之前的值，这就会引发错误。为了解决这个问题，必须保证增加操作是原子的，在JDK1.5之前我们可以使用同步技术来做到这一点。到JDK1.5，java.util.concurrent.atomic包提供了int和long类型的装类，它们可以自动的保证对于他们的操作是原子的并且不需要使用同步。可以阅读这篇文章来了解Java的atomic类。 Java Concurrency API中的Lock接口(Lock interface)是什么？对比同步它有什么优势？Lock接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同的性质，并且可以支持多个相关类的条件对象。 它的优势有： 可以使锁更公平可以使线程在等待锁的时候响应中断可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间可以在不同的范围，以不同的顺序获取和释放锁阅读更多关于锁的例子 什么是Executors框架？Executor框架同java.util.concurrent.Executor 接口在Java 5中被引入。Executor框架是一个根据一组执行策略调用，调度，执行和控制的异步任务的框架。 无限制的创建线程会引起应用程序内存溢出。所以创建一个线程池是个更好的的解决方案，因为可以限制线程的数量并且可以回收再利用这些线程。利用Executors框架可以非常方便的创建一个线程池，阅读这篇文章可以了解如何使用Executor框架创建一个线程池。 什么是阻塞队列？如何使用阻塞队列来实现生产者-消费者模型？java.util.concurrent.BlockingQueue的特性是：当队列是空的时，从队列中获取或删除元素的操作将会被阻塞，或者当队列是满时，往队列里添加元素的操作会被阻塞。 阻塞队列不接受空值，当你尝试向队列中添加空值的时候，它会抛出NullPointerException。 阻塞队列的实现都是线程安全的，所有的查询方法都是原子的并且使用了内部锁或者其他形式的并发控制。 BlockingQueue 接口是java collections框架的一部分，它主要用于实现生产者-消费者问题。 阅读这篇文章了解如何使用阻塞队列实现生产者-消费者问题。 什么是Callable和Future?Java 5在concurrency包中引入了java.util.concurrent.Callable 接口，它和Runnable接口很相似，但它可以返回一个对象或者抛出一个异常。 Callable接口使用泛型去定义它的返回类型。Executors类提供了一些有用的方法去在线程池中执行Callable内的任务。由于Callable任务是并行的，我们必须等待它返回的结果。java.util.concurrent.Future对象为我们解决了这个问题。在线程池提交Callable任务后返回了一个Future对象，使用它我们可以知道Callable任务的状态和得到Callable返回的执行结果。Future提供了get()方法让我们可以等待Callable结束并获取它的执行结果。 阅读这篇文章了解更多关于Callable，Future的例子。 什么是FutureTask?FutureTask是Future的一个基础实现，我们可以将它同Executors使用处理异步任务。通常我们不需要使用FutureTask类，单当我们打算重写Future接口的一些方法并保持原来基础的实现是，它就变得非常有用。我们可以仅仅继承于它并重写我们需要的方法。阅读Java FutureTask例子，学习如何使用它。 7.什么是并发容器的实现？Java集合类都是快速失败的，这就意味着当集合被改变且一个线程在使用迭代器遍历集合的时候，迭代器的next()方法将抛出ConcurrentModificationException异常。 并发容器支持并发的遍历和并发的更新。 主要的类有ConcurrentHashMap, CopyOnWriteArrayList 和CopyOnWriteArraySet，阅读这篇文章了解如何避免ConcurrentModificationException。 Executors类是什么？Executors为Executor，ExecutorService，ScheduledExecutorService，ThreadFactory和Callable类提供了一些工具方法。 Executors可以用于方便的创建线程池。]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[TPS和QPS的区别]]></title>
    <url>%2F2018%2F04%2F27%2FTPS%E5%92%8CQPS%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[一、TPS：Transactions Per Second（每秒传输的事物处理个数），即服务器每秒处理的事务数。TPS包括一条消息入和一条消息出，加上一次用户数据库访问。（业务TPS = CAPS × 每个呼叫平均TPS） TPS是软件测试结果的测量单位。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。 一般的，评价系统性能均以每秒钟完成的技术交易的数量来衡量。系统整体处理能力取决于处理能力最低模块的TPS值。 二、QPS：Queries Per Second每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准，在因特网上，作为域名系统服务器的机器的性能经常用每秒查询率来衡量。 对应fetches/sec，即每秒的响应请求数，也即是最大吞吐能力。 QPS: 每秒钟处理完请求的次数；注意这里是处理完。具体是指发出请求到服务器处理完成功返回结果。可以理解在server中有个counter，每处理一个请求加1，1秒后counter=QPS。 TPS：每秒钟处理完的事务次数，一般TPS是对整个系统来讲的。一个应用系统1s能完成多少事务处理，一个事务在分布式处理中，可能会对应多个请求，对于衡量单个接口服务的处理能力，用QPS比较多。 并发量：系统能同时处理的请求数 RT：响应时间，处理一次请求所需要的平均处理时间 计算关系： QPS = 并发量 / 平均响应时间 并发量 = QPS * 平均响应时间]]></content>
      <categories>
        <category>server</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MarkDown syntax 有道云笔记]]></title>
    <url>%2F2018%2F04%2F20%2FMarkDown-syntax-youdao%2F</url>
    <content type="text"><![CDATA[利用GitHub把个人博客搭建完成了，就想着以后要多写点博客，才对的起GitHub提供的便利。写博客用到的都是markdown语法，因为以前一直用有道云笔记来记录东西。所以熟悉有道云的语法，虽说和主流的markdown语法有很大的出入，但是基本的操作都是有了。有道的流程图功能很强大，但是放到这里不太好用了，真是个很大的遗憾。 一个#是一级标题两个##是二级标题三个###是三级标题四个####是四级标题五个#####是五级标题六个######是六级标题表格1234title1 | header 2 | title3---|---|---row 1 col 1 | row 1 col 2 | row 1 col 3row 2 col 1 | row 2 col 2 | row 2 col 3 title1 header 2 title3 row 1 col 1 row 1 col 2 row 1 col 3 row 2 col 1 row 2 col 2 row 2 col 3 代码用 ``` code ```包围123public static void main()&#123; sout(&quot;这是插入代码&quot;)&#125; 图片1![image](url) 链接1[点这里可以跳转](url) 点这里可以跳转 这个是加黑字体1**这个是加黑字体** 这个是斜体1*这个是斜体* 这个是横线1~~这个是横线~~ ==这个是加背景颜色的字体==1==这个是加背景颜色的字体== 分割线1---是分割线 没有排序的列表1234567891011- a - a.a - a.b - a.b.a - a.b.b - a.b.b.a- b- - b.a- - b.b- - - b.b.a- c a a.a a.b a.b.a a.b.b a.b.b.a b b.a b.b b.b.a c 有序列表1234561. 第一个层级 1. 这是1.1 2. 这是1.2 1. 这是1.2.1 2. 这是1.2.22. 第二个层级 第一个层级 这是1.1 这是1.2 这是1.2.1 这是1.2.2 这是第三个 第二个层级 待办事项12- [ ] 没有完成的作业- [x] 已经完成的工作 没有完成的作业 已经完成的工作 html代码可以执行出来1234567&lt;html&gt;&lt;!--在这里插入内容--&gt;在这里可以写入html的内容&lt;br/&gt;&lt;hr/&gt;&lt;a href=&apos;http://github.com&apos;&gt;点击可以跳转到github&lt;/a&gt;&lt;br/&gt;以上都是html的内容&lt;/html&gt; 在这里可以写入html的内容点击可以跳转到github以上都是html的内容 下面是数学公式和时许图，有道云笔记的功能，好像拿出来不好用了 1E = mc^2 12graph LRA--&gt;B 123sequenceDiagramA-&gt;&gt;B: How are you?B-&gt;&gt;A: Great! 12345678ganttdateFormat YYYY-MM-DDsection S1T1: 2014-01-01, 9dsection S2T2: 2014-01-11, 9dsection S3T3: 2014-01-02, 9d]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F04%2F19%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>搭建blog</category>
      </categories>
  </entry>
</search>
